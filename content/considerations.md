+++
title = "Considerations on transformative AI and explosive growth from a semiconductor-industry perspective"
date = 2023-05-30
description = ""
+++

This is a summary of my entry for the Open Philanthropy AI Worldviews Contest, which you can view in full [here](https://muireall.space/pdf/considerations.pdf).

This essay attempts to bridge a gap between abstract models of AGI timelines and inside views from the semiconductor industry.

Models like those in Cotra 2020 ("Bio Anchors"), Davidson 2021 ("Explosive Growth"), and Davidson 2023 ("Compute-Centric Framework") are grounded in computational and economic abstractions. This is entirely appropriate for medium-to-long-range forecasting, where extrapolating from trends at large is generally more reliable than reasoning about processes in detail.

Even so, I think their cursory accounts of some of their most important parameters are major weaknesses. 
A complementary approach works outward from an inside view---not by immediately pursuing better parameter estimates, but by first trying to uncover as many relevant considerations as possible.
To the extent these considerations make contact with our models' abstractions, we can use them for model inputs; anywhere they don't, we can rethink our models.

The body of this essay is a short scenario-planning exercise meant to demonstrate this approach, considering two pathways by which AI might fail to have transformative impact in the coming decades.
The scenarios are chosen to invite considerations from the semiconductor industry---both its history as a point of comparison and its future as part of the cycle of AI progress.
The industry is as mature as any (perhaps second to parts of the chemical industry), notably in terms of production scale and optimization up against physical limits.
It's grown faster than the global economy for decades, feeding improved hardware back into itself but without explosive (superexponential) growth.
AI aspires to the same scale but is comparatively immature. It leans more heavily on software, which has very different margins and gets less durable competitive advantage from intellectual property. It may also enter a similar feedback cycle, although there's a significant potential difference in how effectively AI outputs can substitute for labor.

I use two scenarios to capture different kinds of obstacles and bottlenecks to AI progress. In the first, firms struggle to capture returns on investment in AI R\&D. In the second, AI progress fails to substantially accelerate the non-AI inputs to AI R\&D. In both scenarios, highly capable AI may be achieved, but it does not arrive suddenly or have transformative impact on short timescales.

This exercise, rather than try to estimate parameters for economic modeling from abstract considerations like the above, attempts to distill the two scenarios into lower-level causal drivers. I also try to identify observable indicators for the degree of influence those drivers may have. Because a comprehensive evaluation of data on these indicators would vastly expand the scope of the essay, I mainly call out examples to clarify meaning or relevance, not to argue the weight of evidence in one direction or another. Appendix A describes the process used to develop scenarios and other elements of the analysis in more detail.

Other appendices provide context and support for some claims that are non-obvious but incidental to the scenario analysis.  Appendix B briefly discusses the pipeline from research to deployment in semiconductor device production. Appendix C is an extended discussion of problems with the nanomechanical computer described in Eric Drexler's *Nanosystems*. Finally, Appendix D contains some related forecasts to more transparently convey my own expectations.

Ideally, this kind of exercise would be done by a panel with overlapping areas of expertise. My effort is far from exhaustive, but I hope it at least shows how this approach might usefully fit into a broader forecasting or planning project. If I wanted to single out a few particular themes I think existing analyses don't fully appreciate:

- Models of transformative change would strongly benefit from deeper inside views.
- Hardware specialization is a meaningful obstacle to rapid growth through paradigm shifts or redeployment of resources.
- A robust open-source community and publicly-owned AI services can dampen AI growth along paths that require large, lumpy capital investment, in part by reducing the potential for AI ventures to capture profits.
- Progress in industry at scale is not limited by "ideas" in the same way that basic research could imaginably be.

[The full document is available here.](https://muireall.space/pdf/considerations.pdf)